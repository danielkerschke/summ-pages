Sharpe, M. J., Chang, C. Y., Liu, M. A., Batchelor, H. M., Mueller, L. E., Jones, J. L., Niv, Y., & Schoenbaum, G. (2017). Dopamine transients are sufficient and necessary for acquisition of model-based associations. Nature Neuroscience. https://doi.org/10.1038/nn.4538.

The paper asks a simple question with big consequences: do brief spikes of dopamine teach only raw “how good” values, or can they also help the brain learn the actual structure of events, so that one neutral cue can point to another and, by inference, to a specific outcome? The authors used sensory preconditioning in rats, where a neutral cue C is followed by another neutral cue X, and only later X is paired with food. Normally, C comes to evoke food seeking by inference. First, they created a blocking situation so that learning C→X would be weak, then turned on dopamine neurons right at the start of X. That tiny burst unblocked learning. Later, rats treated that earlier C as meaning “food is coming,” and this response dropped when the food was made undesirable, which shows they had learned a specific link, not just a vague value. In short, a brief dopamine transient was sufficient to stamp in a cue-to-cue association that supports model-based behavior. 

Next, they asked if dopamine is required for this kind of learning. In a new group, they silenced dopamine neurons only during the handoff from cue B to cue Y in the preconditioning stage. Everything else about training stayed the same, and later both X and Y were paired with food. Rats still learned that X and Y predicted food, which means basic conditioning was fine, but the specific preconditioned link from B was weakened only when dopamine had been silenced at that brief transition. This selective loss shows that dopamine transients are necessary to form the internal map that connects neutral events to each other before any reward shows up. 

Together these results broaden the job description of dopamine. The classic view says dopamine errors attach a single number that reflects how good something is. Here we learn that the same brief signals help build the graph of the world: which events lead to which, and therefore which specific outcome to expect. That fits with reports that dopamine can respond to surprising neutral cues and suggests these signals carry prediction errors about events, not only rewards. The upshot is a cleaner bridge between reinforcement learning ideas and flexible, devaluation-sensitive behavior that depends on knowing “what leads to what,” not only “how much.” 
