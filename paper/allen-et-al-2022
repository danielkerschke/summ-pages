Allen, M., Levy, A., Parr, T., & Friston, K. J. (2022). In the body’s eye: The computational anatomy of interoceptive inference. PLOS Computational Biology, 18(9), e1010490.

We start with an everyday picture. Your body runs on rhythms. Your heart squeezes, then relaxes. Your lungs fill, then empty. When the heart squeezes, a pressure wave shoots through the arteries. That pulse can jostle sensors and briefly change what the brain is feeling from inside the body. The simple idea in this paper is that the brain learns this pattern and uses it. During the squeeze phase, called systole, the brain treats incoming sights and sounds as a little less trustworthy. During the filling phase, called diastole, it treats them as a little more trustworthy. Think of a camera that gets a tiny shake each time you press the button. A smart camera app would lower its sensitivity during the instant of the shake, then bring it back up.
- "Across deep time, animals that could tell “my own pulse just shook me” from “something out there just moved” had a survival edge. Each heartbeat creates a brief internal blast of noise. The heart squeezes, blood surges, pressure sensors in the arteries fire, and tiny movements ripple through the chest, neck, and skull. If the brain treated every flicker during that squeeze as reliable news from the outside world, it would chase phantoms and miss real signals. Evolution’s workaround is simple: use the heartbeat itself as a timing cue. During systole, the squeeze phase, turn the sensory gain down a bit, because the body is loud and the chance of false alarms is high. During diastole, the filling phase, turn the gain back up, because the body is quieter and the odds that a sight or sound is real are better. This rhythmic gating saves energy, reduces false positives, and keeps reflexes from being wasted on self made jolts. It also plays nicely with prediction. The brain expects the systolic jostle, so it discounts it, much like noise canceling headphones subtracting a known hum. Over many generations, creatures that learned this pulse tuned bookkeeping were more accurate in threat detection, more efficient in foraging, and less likely to mistake their own drumbeat for footsteps in the grass. The same logic shows up with other body rhythms too, like breathing and walking, which the brain also uses as clocks to decide when to sample the world most carefully."
	-- That's funny. It's just a tiny discounting, because things that feel like a heartbeat but during systole probably are just that; but if they happen during diastole, they are potentially significant.

There is a straightforward biological path for this. Special pressure sensors in the big arteries, called baroreceptors, fire right when the heart ejects blood. That burst of signals heads to brain regions that track the body’s internal state. The brain can predict this brief internal “thump” and avoid mixing it up with real changes in the outside world. One way to avoid the mix up is to turn down the gain on outside signals for a split second. Audio engineers do this all the time, lowering a microphone’s sensitivity when someone bumps the stand so the bump does not drown out the singer. Your brain can do a similar trick on vision and other senses around each heartbeat.

The model in the paper is a small teaching example that shows how this gating could work in practice. It gives the brain two jobs at once. One job is to guess what is out there, for example, flower or spider. The other job is to guess what the body is doing, for example, systole or diastole, calm or aroused. The model includes a knob called precision. Precision is just how much you trust a stream of evidence. The key move is to let visual precision dip during systole and rise during diastole. With that one move, the agent behaves sensibly. It spots threats faster when aroused, its confidence wobbles a little with the heartbeat, and if you blur its access to internal signals, its heart responses flatten and its expectations skew. None of this needs exotic math. It is what you get when a guesser that cares about accuracy adjusts how much it trusts noisy channels at predictable times.

### The model

Here is the model setup in plain terms. The agent sees pictures that are either calm, like a flower, or arousing, like a spider. It also feels its own cardiac phase, which switches between squeezing and relaxing. The vital knob in the model is called precision. Think of precision as trust in a signal. During the squeeze phase the model lowers visual precision a bit, because that is a noisier moment. During the relaxed phase it raises visual precision again. That is the **only coupling** the authors hard-code between body and world. Everything else is learned as the agent updates its beliefs about what it is seeing and what state its body is in.

What does the model actually show? First, it reproduces familiar patterns of behavior and physiology in a controlled way. When a sudden threat appears, the synthetic heart speeds up and the agent’s expectation of more threats jumps, then both settle. Even during calm periods, the agent’s moment-to-moment threat expectation wiggles with the heartbeat, because evidence is just a touch fuzzier during each squeeze. If you “lesion” the agent by making its inner signals unreliable, its heart response to threat is blunted and its expectations are slightly skewed toward fear during baseline. This side-by-side comparison shows why tracking body signals helps. With good interoception, the agent times its trust in the senses better and its reactions are cleaner.
- So, we show the likely true mechanism, by showing what surprisingly realistic behaviours can emerge from simple assumptions.

**Does this improve the goodness of guesses, and how is that shown?** The authors measure guess quality with a simple yardstick called uncertainty. You can think of uncertainty as how spread out the agent’s beliefs are. They compute it directly from the beliefs the agent holds after each observation. When visual and cardiac signals are both reliable, uncertainty is lower, and confidence is higher. When either stream is made noisy, uncertainty rises. The model also shows that uncertainty itself rises and falls with the cardiac cycle, because the quality of visual evidence rises and falls with that cycle. These patterns tell you the gating rule is useful. By tuning trust over the heartbeat, the agent avoids being misled by predictable noise and ends up with crisper, more stable beliefs across time.

There is one more check that the story hangs together. The model produces synthetic heart traces and standard heart rate variability summaries, and those summaries shift in sensible ways when you change how much the agent trusts inner signals or how strong its arousal prior is. That link from belief settings to physiological readouts is helpful, because it means the same simple mechanism connects perception, confidence, and body rhythms. The work is a proof of principle rather than a final map of the brain. Its value is that it turns a clear biological hunch into a testable framework that explains behavior, confidence, and physiology with the same parts.

### FAQ

- **How does the agent make predictions, and what is it like to be him?** **Why is there anything to doubt at all?** Picture a person looking at very quick, slightly noisy flashes of images while their heart is beating in the background. The agent lives in that world of brief, imperfect glimpses. At any moment it holds graded hunches about two hidden things at once: what the picture is, and what its body state is. Those hunches are just probabilities that shift as new evidence arrives. When a glimpse comes in, the agent asks, “If it were a spider, would a glimpse like this be likely, and if it were a flower, how likely would it be.” *It then nudges its beliefs toward whichever hypothesis makes the glimpse less surprising*. Doubt exists because the evidence is never perfectly clean, and during the squeeze of a heartbeat the model treats vision as a bit noisier, so belief updates are smaller and more cautious. Across many glimpses, beliefs sharpen, confidence rises, and actions like “stay calm” or “gear up” are chosen *to make future evidence more useful*. (To make the next glimpse clearer, the brain quietly steers the body: it may slow the heart and keep breathing slow and even so the picture stays steady, or it may speed the heart for quicker updates and slip in a brief breath hold to cut self-made motion, while attention narrows and eye movements quiet, and it chooses the mix that best reduces doubt in that moment. This mostly changes with uncertainty; when the brain feels unsure, it leans toward quicker heartbeats, steadier or briefly held breath, and tighter focus to grab cleaner, faster samples; when it feels sure, it lets heart and breathing settle and widens attention.) To be that agent feels like having a running inner meter that wobbles toward spider or flower, with a tiny rhythmic flutter of uncertainty in time with the pulse.
	- **This setup descends from predictive processing theory.** The basic idea is that the brain quietly guesses what is out there and what will happen next, then uses the senses to check those guesses. When a guess and the incoming signal disagree, the gap is called a prediction error, and the brain updates its belief to shrink that gap. Precision is simply how much trust the brain puts on a given signal, like a volume knob for errors. If a signal is likely to be noisy at a predictable time, the smart move is to trust it a little less in that window so you do not chase noise. The heartbeat gives such a window, because each squeeze adds a brief internal jolt, so the model turns visual precision down during the squeeze and back up between beats, which helps the agent keep its beliefs stable and useful.
- **What physiological patterns is the model trying to match, and do people show them in real tests?** The target patterns are simple and familiar. Threats speed the heart, quiet images let it slow, and sensitivity to outside signals dips for a split instant during the heart’s squeeze and recovers between beats. The model reproduces those rhythms and links them to what the agent reports, such as choices and confidence. This connects to real measurements from judgment tasks where brief images are timed to the heartbeat and people report what they saw and how sure they feel. In those studies, *accuracy and confidence often drop when a stimulus lands on the squeeze phase*, reaction times shift with arousal, and heart traces show characteristic variability patterns that change with stress or calm. The model generates the same kinds of outputs you can record in a lab, such as choice accuracy across heartbeat phase, confidence time courses, and realistic heart rate and variability summaries, so its claims can be checked against data rather than left as a story.


