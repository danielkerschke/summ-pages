Niv, Y., Daw, N. D., Joel, D., & Dayan, P. (2006). Tonic dopamine: opportunity costs and the control of response vigor. Psychopharmacology. 

The paper starts from a simple headache you can relate to even if you have never been a rat in a Skinner box. Dopamine clearly changes how quickly and energetically animals act. Give them more dopamine and they move faster. Block it and they slow down. Yet most well known theories focus on phasic dopamine bursts that teach which action to choose, not how hard or how fast to do it. So the authors build a model that explains vigor itself with first principles. The key idea is to treat time as costly. Every second you dawdle is a second you could have been earning reward, and that lost earning is an opportunity cost. 

They formalize a very down to earth scenario. At each moment the animal picks two things, not one. It picks what to do, like press a lever, and how quickly to do it, which they represent as a chosen latency. Acting quickly is assumed to cost more effort than acting slowly, so there is a tradeoff. Rewards arrive according to the schedule of the task, and eating also takes time. The goal is to maximize the long run average net reward per unit time, not just the total reward. That average reward rate, call it R, is the background meter of how valuable time currently is. While the animal is busy carrying out an action for τ seconds, it forgoes R·τ units of expected reward. That is the opportunity cost that pushes toward shorter latencies when R is high. 

From that setup they derive a crisp result. Optimal latency is inversely related to the average reward rate. When R goes up, you should act faster across the board, even for unrelated actions like grooming, because time has become expensive. Hunger raises the subjective value of food, which raises R, which shortens latencies everywhere. The model also reproduces classic free operant facts, like hyperbolic relations between reinforcement rate and responding, and matching in concurrent schedules. The math shows why you see faster responding on ratio schedules than on yoked interval schedules, without hand waving. Yes, the rats press the lever more when it pays, because the clock is literally worth more to them. 

They then tie the knob R to biology. The proposal is that tonic dopamine in striatum reports the running average reward rate, effectively the price of time. Raise tonic dopamine and behavior gets more vigorous right away. Deplete or block it and responding slows, especially when the schedule demands many presses per reward. Their simulations mirror classic lesion and pharmacology results. They also separate roles cleanly. Tonic dopamine sets vigor now via opportunity cost. Phasic dopamine teaches which actions are good over experience via prediction errors. This split yields testable predictions, like longer reaction times after accumbens dopamine depletion even before new learning catches up, and shorter latencies in deprivation states because tonic dopamine should be higher. 

Finally, they admit what any honest modeler has to. The timing is simplified, real animals do not pick a latency with godlike precision, and tonic and phasic pathways interact. Still, the core contribution is a normative account that unifies energizing theories of dopamine with reinforcement learning. It says vigor is not a mystical “drive.” It is a rational adjustment to the current average rate of payoff. When time is cheap, you can afford to be slow. When time is expensive, you move. Your nervous system does the accounting with dopamine, because of course it does. 
